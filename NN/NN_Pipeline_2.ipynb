{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a315296",
   "metadata": {},
   "source": [
    "Resources:\n",
    "\n",
    "https://docs.pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "https://machinelearningmastery.com/lstm-for-time-series-prediction-in-pytorch/\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6b3713",
   "metadata": {},
   "source": [
    "#### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "08a2250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "from datetime import datetime, timedelta\n",
    "from ta.momentum import RSIIndicator, StochasticOscillator\n",
    "from ta.trend import SMAIndicator, MACD, CCIIndicator\n",
    "from ta.momentum import WilliamsRIndicator\n",
    "from ta.volume import ChaikinMoneyFlowIndicator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a640f657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0+cu128\n",
      "12.8\n",
      "True\n",
      "1\n",
      "NVIDIA GeForce RTX 4080\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.version.cuda) \n",
    "print(torch.cuda.is_available())   # True if a GPU is detected\n",
    "print(torch.cuda.device_count())   # Number of GPUs available\n",
    "print(torch.cuda.get_device_name(0))  # Name of the first GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfb54f9",
   "metadata": {},
   "source": [
    "#### Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "364e030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_price_data(\n",
    "    ticker: str,\n",
    "    start_date: str,\n",
    "    end_date: str,\n",
    "    pred_target: int,\n",
    "    leadup_days: int = 30,\n",
    "    interval: str = \"1d\",\n",
    "    sma_vals=[10, 20]\n",
    "    \n",
    "):\n",
    "    \"\"\"\n",
    "    Fetches price data with extra leadup_days for indicator warmup,\n",
    "    computes technical indicators, and trims back to the exact start_date.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute leadup start date\n",
    "    start_dt = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    leadup_start_dt = start_dt - timedelta(days=leadup_days)\n",
    "    leadup_start = leadup_start_dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Fetch data\n",
    "    ticker_obj = yf.Ticker(ticker)\n",
    "    df = ticker_obj.history(\n",
    "        start=leadup_start,\n",
    "        end=end_date,\n",
    "        interval=interval,\n",
    "        auto_adjust=False,\n",
    "        actions=False\n",
    "    )\n",
    "\n",
    "    # Ensure columns are consistent\n",
    "    df = df.copy()\n",
    "    df.index = df.index.normalize()\n",
    "    df.columns = df.columns.str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "    # === Add Indicators ===\n",
    "    # SMA\n",
    "    for i in sma_vals:\n",
    "        df[f\"sma_{i}\"] = SMAIndicator(df[\"close\"], window=i).sma_indicator()\n",
    "\n",
    "    # Stochastic Oscillator\n",
    "    stoch = StochasticOscillator(\n",
    "        df[\"high\"], df[\"low\"], df[\"close\"],\n",
    "        window=14, smooth_window=3\n",
    "    )\n",
    "    df[\"stoch_k\"] = stoch.stoch()\n",
    "    df[\"stoch_d\"] = stoch.stoch_signal()\n",
    "\n",
    "    # MACD\n",
    "    macd = MACD(df[\"close\"], window_slow=26, window_fast=12, window_sign=9)\n",
    "    df[\"macd\"] = macd.macd()\n",
    "    df[\"macd_signal\"] = macd.macd_signal()\n",
    "    df[\"macd_hist\"] = macd.macd_diff()\n",
    "\n",
    "    # CCI\n",
    "    df[\"cci\"] = CCIIndicator(df[\"high\"], df[\"low\"], df[\"close\"], window=20).cci()\n",
    "\n",
    "    # Williams %R\n",
    "    df[\"williams_r\"] = WilliamsRIndicator(df[\"high\"], df[\"low\"], df[\"close\"], lbp=14).williams_r()\n",
    "\n",
    "    # RSI\n",
    "    df[\"rsi\"] = RSIIndicator(df[\"close\"], window=14).rsi()\n",
    "\n",
    "    # ADOSC (Chaikin Money Flow)\n",
    "    df[\"adosc\"] = ChaikinMoneyFlowIndicator(\n",
    "        high=df[\"high\"],\n",
    "        low=df[\"low\"],\n",
    "        close=df[\"close\"],\n",
    "        volume=df[\"volume\"],\n",
    "        window=20\n",
    "    ).chaikin_money_flow()\n",
    "    \n",
    "    # Target value\n",
    "    # df[f\"{pred_target}-day_target\"] = (df[\"close\"].shift(-pred_target) - df[\"close\"]) / df[\"close\"]\n",
    "    \n",
    "    # Target: cumulative future log return over pred_target days\n",
    "    daily_log_return = np.log(df[\"close\"] / df[\"close\"].shift(1))\n",
    "    df[f\"{pred_target}_day_target\"] = (\n",
    "        daily_log_return.rolling(pred_target).sum().shift(-pred_target)\n",
    "    )\n",
    "\n",
    "    # Drop NaNs caused by indicator warmup\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Trim back to the actual start_date (remove leadup)\n",
    "    # df = df[df.index >= start_date]\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46627ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sequences(df, target_col ,feature_cols, seq_len=10):\n",
    "    X, y = [], []\n",
    "    \n",
    "    values = df[feature_cols].values\n",
    "    targets = target_col.values\n",
    "\n",
    "    for i in range(len(df) - seq_len):\n",
    "        X.append(values[i:i+seq_len])\n",
    "        y.append(targets[i+seq_len])\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1495256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save_metrics(metrics_df, target_horizon, save_table=True):\n",
    "      \"\"\"Creates and saves three metric plots:\n",
    "         (1) RMSE + MAE together\n",
    "         (2) Directional Accuracy\n",
    "         (3) Spearman Correlation\n",
    "         Files are named using the prediction horizon.\n",
    "      \"\"\"\n",
    "      \n",
    "      # Create directory name and ensure it exists\n",
    "      folder_name = f\"results_target_{target_horizon}\"\n",
    "      os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "      years = metrics_df[\"year\"]\n",
    "\n",
    "      # --- Plot 1: RMSE + MAE ---\n",
    "      fig1, ax1 = plt.subplots(figsize=(8, 4))\n",
    "      ax1.plot(years, metrics_df[\"rmse\"], marker=\"o\", label=\"RMSE\")\n",
    "      ax1.plot(years, metrics_df[\"mae\"], marker=\"o\", label=\"MAE\")\n",
    "      ax1.set_title(f\"RMSE & MAE ({target_horizon}-Day Horizon)\")\n",
    "      ax1.set_xlabel(\"Year\")\n",
    "      ax1.set_ylabel(\"Error Value\")\n",
    "      ax1.grid(True, alpha=0.3)\n",
    "      ax1.legend()\n",
    "      \n",
    "      filename1 = f\"metrics_target_{target_horizon}_RMSE_MAE.png\"\n",
    "      fig1.tight_layout()\n",
    "      fig1.savefig(os.path.join(folder_name, \"RMSE_MAE.png\"), dpi=150)\n",
    "      plt.close(fig1)\n",
    "\n",
    "\n",
    "      # --- Plot 2: Directional Accuracy ---\n",
    "      \n",
    "      fig2, ax2 = plt.subplots(figsize=(8, 4))\n",
    "      ax2.plot(years, metrics_df[\"directional_accuracy (%)\"], marker=\"s\", linestyle=\"--\")\n",
    "      ax2.set_ylim(0, 100)\n",
    "      ax2.set_title(f\"Directional Accuracy ({target_horizon}-Day Horizon)\")\n",
    "      ax2.set_xlabel(\"Year\")\n",
    "      ax2.set_ylabel(\"Directional Accuracy (%)\")\n",
    "      ax2.grid(True, alpha=0.3)\n",
    "\n",
    "      filename2 = f\"metrics_target_{target_horizon}_Directional_Accuracy.png\"\n",
    "      fig2.tight_layout()\n",
    "      fig2.savefig(os.path.join(folder_name, \"Directional_Accuracy.png\"), dpi=150)\n",
    "      plt.close(fig2)\n",
    "\n",
    "\n",
    "      # --- Plot 3: Spearman Correlation ---\n",
    "      fig3, ax3 = plt.subplots(figsize=(8, 4))\n",
    "      ax3.plot(years, metrics_df[\"spearman\"], marker=\"s\", linestyle=\":\")\n",
    "      ax3.set_title(f\"Spearman Correlation ({target_horizon}-Day Horizon)\")\n",
    "      ax3.set_xlabel(\"Year\")\n",
    "      ax3.set_ylabel(\"Spearman\")\n",
    "      ax3.grid(True, alpha=0.3)\n",
    "\n",
    "      filename3 = f\"metrics_target_{target_horizon}_Spearman.png\"\n",
    "      fig3.tight_layout()\n",
    "      fig3.savefig(os.path.join(folder_name, \"Spearman.png\"), dpi=150)\n",
    "      plt.close(fig3)\n",
    "      \n",
    "      \n",
    "      # save the df for good measure\n",
    "      df_file = f\"metrics_target_{target_horizon}.csv\"\n",
    "      # === optional table save ===\n",
    "      if save_table:\n",
    "        metrics_df.to_csv(os.path.join(folder_name, \"metrics.csv\"), index=False)\n",
    "      \n",
    "\n",
    "      print(\"\\nSaved plots:\")\n",
    "      print(f\" - {filename1}\")\n",
    "      print(f\" - {filename2}\")\n",
    "      print(f\" - {filename3}\")\n",
    "      print(f\" - {df_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd844c96",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5355b881",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMPredictor(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, num_layers=2, dropout=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len, features)\n",
    "        output, (hidden, _) = self.lstm(x)\n",
    "        last_hidden = hidden[-1]\n",
    "        return self.fc(last_hidden)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cb37c4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_experiment(model: LSTMPredictor, metrics: pd.DataFrame, target_horizon: int):\n",
    "    folder = f\"results_target_{target_horizon}\"\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # ----- Save model -----\n",
    "    model_path = os.path.join(folder, f\"model_target_{target_horizon}.pt\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    # ----- Save metrics -----\n",
    "    metrics.to_csv(os.path.join(folder, \"metrics.csv\"), index=False)\n",
    "\n",
    "    print(f\"\\nSaved model and metrics to: {folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1545fc",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "244f5324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_forward_training_loop(df, target_col, feature_cols, \n",
    "    SEQ_LEN=10,\n",
    "    START_YEAR=2015,\n",
    "    END_YEAR=2025,\n",
    "    LEARNING_RATE=0.001,\n",
    "    HIDDEN_DIM=64,\n",
    "    NUM_LAYERS=2,\n",
    "    DROPOUT=0.2,\n",
    "    EPOCHS=10):\n",
    "    \n",
    "    \"\"\"\n",
    "    Walk Forward logic:\n",
    "\n",
    "    | Window | Train     | Test | Scaling Rule                 |\n",
    "    | ------ | --------- | ---- | ---------------------------- |\n",
    "    | #1     | 2015-2017 | 2018 | Fit scaler only on 2015-2017 |\n",
    "    | #2     | 2015-2018 | 2019 | Fit scaler only on 2015-2018 |\n",
    "    | #3     | 2015-2019 | 2020 | Fit scaler only on 2015-2019 |\n",
    "    etc...\n",
    "    \n",
    "    This must be done to avoid data-leakage\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    years = list(range(START_YEAR, END_YEAR))  # test years\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for year in years:\n",
    "        print(f\"\\n=== WALK {year} ===\")\n",
    "\n",
    "        # Determine the true first trading day of the year\n",
    "        test_start = df[df.index >= f\"{year}-01-01\"].index.min()\n",
    "        if pd.isna(test_start):\n",
    "            print(f\"[SKIP] No rows available for year {year}\")\n",
    "            continue\n",
    "\n",
    "        train = df[df.index < test_start]\n",
    "        test  = df[df.index >= test_start]\n",
    "\n",
    "        # ðŸ”¥ Fix: ensure training data exists BEFORE scaling\n",
    "        if len(train) < SEQ_LEN:\n",
    "            print(f\"[WAIT] Not enough historical rows before {test_start} \"\n",
    "                f\"({len(train)} available, need â‰¥ {SEQ_LEN}). Skipping this boundary.\")\n",
    "            continue\n",
    "\n",
    "        # Scaling\n",
    "        scaler = StandardScaler()\n",
    "        scaled_train = scaler.fit_transform(train[feature_cols])\n",
    "        scaled_test  = scaler.transform(test[feature_cols])\n",
    "\n",
    "        # Assign scaled values\n",
    "        train_scaled = train.copy()\n",
    "        test_scaled  = test.copy()\n",
    "        train_scaled[feature_cols] = scaled_train\n",
    "        test_scaled[feature_cols] = scaled_test\n",
    "\n",
    "        # Make sequences\n",
    "        X_train, y_train = make_sequences(train_scaled, target_col, feature_cols, SEQ_LEN)\n",
    "        X_test,  y_test  = make_sequences(test_scaled,  target_col, feature_cols, SEQ_LEN)\n",
    "\n",
    "        # Convert to tensors\n",
    "        X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "        y_train_t = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "        X_test_t  = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "        loader = DataLoader(TensorDataset(X_train_t, y_train_t), batch_size=32, shuffle=True)\n",
    "\n",
    "        # Train a fresh LSTM\n",
    "        model = LSTMPredictor(\n",
    "            input_dim=len(feature_cols), \n",
    "            hidden_dim=HIDDEN_DIM,\n",
    "            num_layers=NUM_LAYERS,\n",
    "            dropout=DROPOUT\n",
    "        )\n",
    "        opt = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "        loss_fn = nn.MSELoss()\n",
    "\n",
    "        for epoch in range(EPOCHS):\n",
    "            for xb, yb in loader:\n",
    "                opt.zero_grad()\n",
    "                pred = model(xb)\n",
    "                loss = loss_fn(pred, yb)\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Predict full test window\n",
    "        preds = model(X_test_t).detach().numpy().flatten()\n",
    "        pred_dates = test_scaled.index[SEQ_LEN:]\n",
    "\n",
    "        results.append(pd.DataFrame({\n",
    "            \"date\": pred_dates,\n",
    "            \"prediction\": preds,\n",
    "            \"actual\": y_test\n",
    "        }))\n",
    "\n",
    "    return results, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666c8aa9",
   "metadata": {},
   "source": [
    "#### Operation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1f0742e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== WALK 2015 ===\n",
      "\n",
      "=== WALK 2016 ===\n",
      "\n",
      "=== WALK 2017 ===\n",
      "\n",
      "=== WALK 2018 ===\n",
      "\n",
      "=== WALK 2019 ===\n",
      "\n",
      "=== WALK 2020 ===\n",
      "\n",
      "=== WALK 2021 ===\n"
     ]
    }
   ],
   "source": [
    "#INIT PARAMS\n",
    "    # Dataset/Time\n",
    "TICKER = \"AMZN\"\n",
    "START = \"2015-01-01\"\n",
    "END = \"2025-01-01\"\n",
    "Y_START = 2015\n",
    "Y_END = 2022\n",
    "WARMUP = 70\n",
    "TARGET = 30\n",
    "    # Model\n",
    "LOOKBACK = 10\n",
    "DIM = 64\n",
    "LAYERS = 2\n",
    "DROPOUT = 0.2\n",
    "LEARNING_RATE = 0.001\n",
    "# 1. Load full data\n",
    "df = load_price_data(\n",
    "    ticker=TICKER,\n",
    "    start_date=START,\n",
    "    end_date=END,\n",
    "    leadup_days=WARMUP,\n",
    "    pred_target=TARGET\n",
    ")\n",
    "\n",
    "# 2. Create walk-forward boundary\n",
    "\n",
    "# leave last two years for final testing untouched during training.\n",
    "train_df = df[df.index < \"2023-01-01\"]\n",
    "test_df  = df[df.index >= \"2023-01-01\"]\n",
    "\n",
    "\n",
    "# 3. Train the model using WalkForward testing split\n",
    "# use all columns as features except target column\n",
    "feature_cols = [col for col in df.columns if col not in [f\"{TARGET}_day_target\"]]\n",
    "target_col = df[f\"{TARGET}_day_target\"]\n",
    "\n",
    "results, model = walk_forward_training_loop(\n",
    "    train_df, target_col, \n",
    "    feature_cols, \n",
    "    SEQ_LEN=LOOKBACK, \n",
    "    START_YEAR=Y_START, \n",
    "    END_YEAR=Y_END, \n",
    "    LEARNING_RATE= LEARNING_RATE, \n",
    "    HIDDEN_DIM= DIM, \n",
    "    NUM_LAYERS= LAYERS, \n",
    "    DROPOUT= DROPOUT\n",
    "    \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2b475003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>directional_accuracy (%)</th>\n",
       "      <th>spearman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>0.112573</td>\n",
       "      <td>0.088688</td>\n",
       "      <td>49.80</td>\n",
       "      <td>0.130792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>0.631487</td>\n",
       "      <td>0.598403</td>\n",
       "      <td>34.19</td>\n",
       "      <td>0.111015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>0.297951</td>\n",
       "      <td>0.259338</td>\n",
       "      <td>30.53</td>\n",
       "      <td>-0.036511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>0.213248</td>\n",
       "      <td>0.186350</td>\n",
       "      <td>70.78</td>\n",
       "      <td>0.019047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>0.202947</td>\n",
       "      <td>0.170748</td>\n",
       "      <td>43.29</td>\n",
       "      <td>0.066105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.348165</td>\n",
       "      <td>0.324884</td>\n",
       "      <td>23.59</td>\n",
       "      <td>0.190341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021</td>\n",
       "      <td>0.125810</td>\n",
       "      <td>0.100786</td>\n",
       "      <td>52.13</td>\n",
       "      <td>0.211270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year      rmse       mae  directional_accuracy (%)  spearman\n",
       "0  2015  0.112573  0.088688                     49.80  0.130792\n",
       "1  2016  0.631487  0.598403                     34.19  0.111015\n",
       "2  2017  0.297951  0.259338                     30.53 -0.036511\n",
       "3  2018  0.213248  0.186350                     70.78  0.019047\n",
       "4  2019  0.202947  0.170748                     43.29  0.066105\n",
       "5  2020  0.348165  0.324884                     23.59  0.190341\n",
       "6  2021  0.125810  0.100786                     52.13  0.211270"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_stats = []\n",
    "\n",
    "for df_year in results:  # each entry is a year dataframe\n",
    "\n",
    "    year = df_year['date'].iloc[0].year  # extract year from first row's date\n",
    "\n",
    "    preds = df_year[\"prediction\"].values\n",
    "    actual = df_year[\"actual\"].values\n",
    "\n",
    "    # Metrics\n",
    "    rmse = np.sqrt(mean_squared_error(actual, preds))\n",
    "    mae = mean_absolute_error(actual, preds)\n",
    "    \n",
    "    # directional accuracy\n",
    "    direction_accuracy = (np.sign(preds) == np.sign(actual)).mean()\n",
    "\n",
    "    # Spearman correlation (ignore NaNs)\n",
    "    spearman_val, _ = spearmanr(actual, preds, nan_policy='omit')\n",
    "\n",
    "    year_stats.append({\n",
    "        \"year\": year,\n",
    "        \"rmse\": rmse,\n",
    "        \"mae\": mae,\n",
    "        \"directional_accuracy (%)\": round(direction_accuracy * 100, 2),\n",
    "        \"spearman\": spearman_val\n",
    "    })\n",
    "\n",
    "# Convert results into a table\n",
    "metrics_df = pd.DataFrame(year_stats).sort_values(\"year\").reset_index(drop=True)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfd55c1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4f47da16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved plots:\n",
      " - metrics_target_30_RMSE_MAE.png\n",
      " - metrics_target_30_Directional_Accuracy.png\n",
      " - metrics_target_30_Spearman.png\n",
      " - metrics_target_30.csv\n",
      "\n",
      "Saved model and metrics to: results_target_30\n"
     ]
    }
   ],
   "source": [
    "plot_and_save_metrics(metrics_df, TARGET)\n",
    "save_experiment(model, metrics_df, TARGET)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
